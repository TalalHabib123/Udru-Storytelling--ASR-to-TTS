{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "d:\\Project\\Udru-Storytelling--ASR-to-TTS\\backend\\.venv\\Lib\\site-packages\\transformers\\models\\whisper\\generation_whisper.py:512: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "You have passed task=translate, but also have set `forced_decoder_ids` to [[1, None], [2, 50360]] which creates a conflict. `forced_decoder_ids` will be ignored in favor of task=translate.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribed audio:  ایک لڑکا جس کے نام دولا تھا اور وہ مرگیا تھا\n",
      "Audio file path: synthesized_audio/dummy3.wav\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'status': 'success',\n",
       " 'message': 'Pipeline processed successfully',\n",
       " 'file_id': 'dummy3',\n",
       " 'audio_url': '/get-audio/dummy3',\n",
       " 'story': 'دولا نامی ایک بچہ بہت اچھا اور شُرِر تھا۔  ہر کسی کی دل میں جگہ رکھتا تھا۔ مگر ایک دن، اس کے جسم کو ایک غیر معمولی بیماری نے آگیا جس سے وہ بیمار ہو گیا۔\\n\\nآشپز خانے میں رات گھڑی کے وقت، دولا کی ماں نے اُس کی آنکھوں میں ایک غیر عادی چمک دیکھی۔  وہ بچہ کھڑا ہے اور کچھ کہنے لگا، مگر اس کی آواز ایک نرالے طرز پر تھی جو ان کی سمجھ سے باہر تھا۔\\n\\nدولا کے جسم کا رنگ گھٹ گیا اور وہ کمزور ہو گیا۔ ماں نے اپنے بیٹے کو محبت سے گھیر لیا، لیکن دولا اب بھی کچھ کہہ رہا تھا۔ وہ \"میں چلا جاؤں گا\" بول رہا تھا۔  \\n\\nدہلیز پر ایک غریب اور تاریک ڈھال نظر آئی، جیسے دولا کی روح ان سے جدا ہو رہی ہے۔ \\n\\n\\n'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "from app.utils.audio.tts.audio_synthesis import translate_text_to_audio\n",
    "from app.utils.audio.asr.translate_audio import transcribe_audio\n",
    "\n",
    "def query_llama_with_ollama(system_prompt, user_prompt):\n",
    "    \"\"\"\n",
    "    Sends a prompt to LLaMA 3.2 via Ollama and streams the response.\n",
    "    \"\"\"\n",
    "    url = \"http://localhost:11434/api/generate\"\n",
    "    full_prompt = f\"{system_prompt}\\n\\n{user_prompt}\"\n",
    "    payload = {\n",
    "        \"model\": \"gemma2\",\n",
    "        \"prompt\": full_prompt,\n",
    "        \"stream\": True\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        with requests.post(url, json=payload, stream=True) as response:\n",
    "            if response.status_code == 200:\n",
    "                for line in response.iter_lines():\n",
    "                    if line:\n",
    "                        decoded_line = line.decode('utf-8')\n",
    "                        json_line = json.loads(decoded_line)\n",
    "                        if 'response' in json_line:\n",
    "                            yield json_line['response']\n",
    "            else:\n",
    "                print(f\"Error: {response.status_code} - {response.text}\")\n",
    "                yield f\"Error: Failed to get response from LLaMA. Status code: {response.status_code}\"\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Request error: {e}\")\n",
    "        yield \"Error: An error occurred while making the request.\"\n",
    "\n",
    "def process_pipeline(file_path: str, file_id: str):\n",
    "    try:\n",
    "        transcribed_audio = transcribe_audio(file_path)\n",
    "        if not transcribed_audio:\n",
    "            raise Exception(\"Error transcribing audio\")\n",
    "        print(f\"Transcribed audio: {transcribed_audio}\")\n",
    "        system_prompt = \"\"\"You are a storytelling AI assistant that writes stories in Urdu script.\n",
    "        You need to write a creative story in Urdu based on the topic and theme provided by the user.\n",
    "        Make the story interesting and fluent, and do not use any words outside of the Urdu script.\n",
    "        Limit the story to a maximum length of 200 words.\n",
    "        Always start the story with a proper introduction.\n",
    "        Never end the story abruptly, and always conclude it logically.\n",
    "        Absolutely never include a word that is not in Urdu font.\"\"\"\n",
    "\n",
    "        theme = \"horror\"\n",
    "        topic = \"  [ ایک شرارتی بلی] \"\n",
    "\n",
    "        user_prompt = f\"\"\"تھییم: [{theme}]\n",
    "        موضوع: [{transcribed_audio}]\n",
    "        اب اردو رسم الخط میں کہانی لکھیں:\"\"\"\n",
    "\n",
    "        story = \"\"\n",
    "        for response in query_llama_with_ollama(system_prompt, user_prompt):\n",
    "            story += response\n",
    "\n",
    "        audio_file_path = translate_text_to_audio(story, file_id)\n",
    "\n",
    "        if not audio_file_path:\n",
    "            raise Exception(\"Error translating text to audio\")\n",
    "        print(f\"Audio file path: {audio_file_path}\")\n",
    "\n",
    "        response = {\n",
    "            \"status\": \"success\",\n",
    "            \"message\": \"Pipeline processed successfully\",\n",
    "            \"file_id\": file_id,\n",
    "            # URL to download the audio file Add the server URL before this in the frontend\n",
    "            \"audio_url\": f\"/get-audio/{file_id}\",\n",
    "            \"story\": story,\n",
    "        }\n",
    "\n",
    "        return response\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing pipeline: {e}\")\n",
    "        response = {\n",
    "            \"status\": \"error\",\n",
    "            \"message\": \"Error processing pipeline\",\n",
    "            \"error\": str(e)\n",
    "        }\n",
    "        return response\n",
    "\n",
    "process_pipeline(\"test.ogg\", \"dummy3\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
